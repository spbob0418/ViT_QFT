{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from timm.data import Mixup\n",
    "\n",
    "def kl_divergence(p, q):\n",
    "    epsilon = 1e-10\n",
    "    p = p + epsilon\n",
    "    q = q + epsilon\n",
    "    kl = torch.sum(p * torch.log(p / q))\n",
    "    return kl.item()\n",
    "\n",
    "# Set default dtype to fp32\n",
    "torch.set_default_dtype(torch.float32)\n",
    "\n",
    "# Define mixup function\n",
    "mixup_fn = Mixup(\n",
    "    mixup_alpha=0.8, cutmix_alpha=1.0, cutmix_minmax=None,\n",
    "    prob=1.0, switch_prob=0.5, mode='batch',\n",
    "    label_smoothing=0.1, num_classes=1000)\n",
    "\n",
    "# Data transformations\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    # Normalization with mean and std for ImageNet\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = datasets.ImageFolder('/data/ILSVRC2012/train', transform=train_transform)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Load ViT model\n",
    "model = timm.create_model('vit_small_patch16_224', pretrained=True)\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "# Initialize clusters\n",
    "clusters = []\n",
    "\n",
    "# Set threshold k (adjust as needed)\n",
    "k = 0.1\n",
    "\n",
    "# Process data\n",
    "for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "    # Limit number of batches for testing\n",
    "    if batch_idx >= 10:\n",
    "        break\n",
    "\n",
    "    # Apply mixup\n",
    "    images, labels = mixup_fn(images, labels)\n",
    "\n",
    "    images = images.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Get patch embeddings\n",
    "        x = model.patch_embed(images)  # x is [B, num_patches, embed_dim]\n",
    "\n",
    "        B, num_patches, embed_dim = x.shape\n",
    "\n",
    "        # For each image in the batch\n",
    "        for i in range(B):\n",
    "            # For each patch in the image\n",
    "            for j in range(num_patches):\n",
    "                patch_vec = x[i, j, :]  # Shape: [embed_dim]\n",
    "\n",
    "                # Normalize to get distribution\n",
    "                p = patch_vec\n",
    "                p = p - p.min()  # Ensure non-negative\n",
    "                p = p / p.sum()  # Sum to 1\n",
    "\n",
    "                # Ensure no zeros\n",
    "                p = p + 1e-10\n",
    "                p = p / p.sum()\n",
    "\n",
    "                assigned = False\n",
    "\n",
    "                # For each cluster\n",
    "                for cluster in clusters:\n",
    "                    q = cluster['center']\n",
    "                    kl = kl_divergence(p, q)\n",
    "\n",
    "                    if kl <= k:\n",
    "                        # Assign to cluster\n",
    "                        cluster['elements'].append(p)\n",
    "                        cluster['distances'].append(kl)\n",
    "                        # Update cluster center\n",
    "                        n = len(cluster['elements'])\n",
    "                        cluster['center'] = (cluster['center'] * (n - 1) + p) / n\n",
    "                        assigned = True\n",
    "                        break\n",
    "\n",
    "                if not assigned:\n",
    "                    # Create new cluster\n",
    "                    clusters.append({\n",
    "                        'center': p,\n",
    "                        'elements': [p],\n",
    "                        'distances': []\n",
    "                    })\n",
    "\n",
    "    print(f\"Processed batch {batch_idx+1}\")\n",
    "\n",
    "# After processing, rank clusters by number of elements\n",
    "clusters_sorted = sorted(clusters, key=lambda x: len(x['elements']), reverse=True)\n",
    "\n",
    "# For the top cluster\n",
    "top_cluster = clusters_sorted[0]\n",
    "num_elements = len(top_cluster['elements'])\n",
    "print(f\"Top cluster has {num_elements} elements.\")\n",
    "\n",
    "# Compute average and standard deviation of distances\n",
    "if top_cluster['distances']:\n",
    "    distances = top_cluster['distances']\n",
    "    avg_distance = sum(distances) / len(distances)\n",
    "    std_distance = np.std(distances)\n",
    "else:\n",
    "    avg_distance = 0\n",
    "    std_distance = 0\n",
    "\n",
    "print(f\"Average distance to center: {avg_distance}\")\n",
    "print(f\"Standard deviation of distances: {std_distance}\")\n",
    "\n",
    "# Output the 384-dimensional cluster center\n",
    "cluster_center = top_cluster['center']\n",
    "print(\"Cluster center values:\")\n",
    "print(cluster_center.cpu().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Selecting images from class folders: 100%|██████████| 1000/1000 [00:01<00:00, 915.50it/s]\n",
      "Processing images for mode calculation: 100%|██████████| 10000/10000 [33:55<00:00,  4.91it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pixel frequency table:\n",
      "Pixel: (255, 255, 255), Count: 34984175\n",
      "Pixel: (0, 0, 0), Count: 20129399\n",
      "Pixel: (1, 1, 1), Count: 5483754\n",
      "Pixel: (254, 254, 254), Count: 4642243\n",
      "Pixel: (2, 2, 2), Count: 2891657\n",
      "Pixel: (253, 253, 253), Count: 2116617\n",
      "Pixel: (3, 3, 3), Count: 1753231\n",
      "Pixel: (4, 4, 4), Count: 1593433\n",
      "Pixel: (5, 5, 5), Count: 1371965\n",
      "Pixel: (6, 6, 6), Count: 1283805\n",
      "Pixel: (7, 7, 7), Count: 1217280\n",
      "Pixel: (8, 8, 8), Count: 1199120\n",
      "Pixel: (252, 252, 252), Count: 1086824\n",
      "Pixel: (255, 255, 253), Count: 1011988\n",
      "Pixel: (0, 0, 2), Count: 992489\n",
      "Pixel: (9, 9, 9), Count: 977431\n",
      "Pixel: (10, 10, 10), Count: 906612\n",
      "Pixel: (13, 13, 13), Count: 898993\n",
      "Pixel: (11, 11, 11), Count: 869029\n",
      "Pixel: (246, 239, 247), Count: 824321\n",
      "Pixel: (254, 255, 255), Count: 789671\n",
      "Pixel: (12, 12, 12), Count: 786587\n",
      "Pixel: (251, 251, 251), Count: 739224\n",
      "Pixel: (16, 16, 16), Count: 737744\n",
      "Pixel: (14, 14, 14), Count: 727069\n",
      "Pixel: (15, 15, 15), Count: 682276\n",
      "Pixel: (17, 17, 17), Count: 654971\n",
      "Pixel: (1, 0, 0), Count: 646595\n",
      "Pixel: (248, 248, 248), Count: 637795\n",
      "Pixel: (2, 2, 0), Count: 633524\n",
      "Most common pixel: (255, 255, 255)\n",
      "Patch saved to output_patch.npy\n",
      "Visualization image saved as 'patch_visualization.png'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 데이터 경로 설정\n",
    "data_path = '/data/ILSVRC2012/train'\n",
    "output_path = 'output_patch.npy'\n",
    "\n",
    "# 클래스 폴더 확인\n",
    "class_folders = [os.path.join(data_path, folder) for folder in os.listdir(data_path) if os.path.isdir(os.path.join(data_path, folder))]\n",
    "\n",
    "\n",
    "# 각 클래스에서 10개의 랜덤 샘플 선택\n",
    "random.seed(42)  # 재현성을 위해 시드 설정\n",
    "selected_images = []\n",
    "for folder in tqdm(class_folders, desc=\"Selecting images from class folders\"):\n",
    "    images = [os.path.join(folder, file) for file in os.listdir(folder) if file.endswith(('.JPEG', '.png'))]\n",
    "    selected_images.extend(random.sample(images, min(10, len(images))))\n",
    "\n",
    "\n",
    "\n",
    "# 최빈값 계산 함수 정의\n",
    "def calculate_mode_pixel(image_paths):\n",
    "    pixel_list = []\n",
    "\n",
    "    for image_path in tqdm(image_paths, desc=\"Processing images for mode calculation\"):\n",
    "        with Image.open(image_path) as img:\n",
    "            img = img.convert('RGB')  # RGB로 변환\n",
    "            pixels = np.array(img).reshape(-1, 3)  # 픽셀을 [R, G, B] 형태로 변환\n",
    "            pixel_list.extend([tuple(pixel) for pixel in pixels])\n",
    "\n",
    "    # 픽셀 최빈값 계산\n",
    "    pixel_counter = Counter(pixel_list)\n",
    "    print(\"Pixel frequency table:\")\n",
    "    for pixel, count in pixel_counter.most_common(30):  # 상위 10개만 출력\n",
    "        print(f\"Pixel: {pixel}, Count: {count}\")\n",
    "\n",
    "    most_common_pixel = pixel_counter.most_common(1)[0][0]\n",
    "    return most_common_pixel\n",
    "\n",
    "# 최빈값 계산\n",
    "total_most_common_pixel = calculate_mode_pixel(selected_images)\n",
    "print(f\"Most common pixel: {total_most_common_pixel}\")\n",
    "\n",
    "# 최빈값으로 이루어진 이미지 패치 생성\n",
    "def create_patch(most_common_pixel, size=(256, 256)):\n",
    "    patch = np.full((size[0], size[1], 3), most_common_pixel, dtype=np.uint8)\n",
    "    return patch\n",
    "\n",
    "patch = create_patch(total_most_common_pixel)\n",
    "\n",
    "# 넘파이 파일로 저장\n",
    "np.save(output_path, patch)\n",
    "print(f\"Patch saved to {output_path}\")\n",
    "\n",
    "# 시각화를 위해 PIL로 저장 (옵션)\n",
    "Image.fromarray(patch).save('patch_visualization.png')\n",
    "print(\"Visualization image saved as 'patch_visualization.png'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
